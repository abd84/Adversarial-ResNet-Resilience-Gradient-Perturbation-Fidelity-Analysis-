{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# FGSM Attack Function\n\ndef fgsm_attack(model, loss_fn, image, label, epsilon):\n    image.requires_grad = True\n    output = model(image)\n    loss = loss_fn(output, label)\n    model.zero_grad()\n    loss.backward()\n    grad = image.grad.data\n    perturbed_image = image + epsilon * grad.sign()\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    return perturbed_image\n\n\n#  FGSM + Gaussian Noise\ndef fgsm_gaussian_attack(model, loss_fn, image, label, epsilon, sigma=0.1):\n    image.requires_grad = True\n    output = model(image)\n    loss = loss_fn(output, label)\n    model.zero_grad()\n    loss.backward()\n    noise = torch.randn_like(image) * sigma\n    perturbed_image = image + epsilon * noise\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    return perturbed_image\n\n\n# Load Pretrained ResNet18 Adapted for MNIST\n\nmodel = models.resnet18(pretrained=True)\n\n# Replace first and last layers to match MNIST input size (1 channel) and 10 classes\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\nmodel.fc = nn.Linear(model.fc.in_features, 10)\n\nmodel = model.to(device)\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),    \n    transforms.ToTensor(),\n])\n\ntest_loader = DataLoader(\n    datasets.MNIST('.', download=True, train=False, transform=transform),\n    batch_size=1,\n    shuffle=True\n)\n\n\n# MNIST Train Data for Fine-Tuning\n\ntrain_loader = DataLoader(\n    datasets.MNIST('.', download=True, train=True, transform=transform),\n    batch_size=64,\n    shuffle=True\n)\n\n\n#Fine-tune on MNIST\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nloss_fn = nn.CrossEntropyLoss()\n\nprint(\"Fine-tuning pretrained ResNet18 on MNIST for 1 epoch...\")\nmodel.train()\nfor epoch in range(1):  \n    running_loss = 0.0\n    for data, target in train_loader:\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_fn(output, target)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n\nprint(\"Fine-tuning complete.\")\n\n\ntorch.save(model.state_dict(), 'finetuned_resnet18_mnist.pth')\nprint(\"Model saved as 'finetuned_resnet18_mnist.pth'.\")\n\n# Evaluate\nmodel.eval()\nepsilon = 0.25\nclean_correct = 0\nfgsm_correct = 0\ngaussian_correct = 0\ntotal_samples = 0  \n\nfor i, (data, target) in enumerate(test_loader):\n    data, target = data.to(device), target.to(device)\n\n    # Clean accuracy\n    output = model(data)\n    pred = output.argmax(dim=1)\n    clean_correct += pred.eq(target).sum().item()\n\n    # FGSM\n    adv_data = fgsm_attack(model, loss_fn, data.clone(), target, epsilon)\n    adv_output = model(adv_data)\n    fgsm_pred = adv_output.argmax(dim=1)\n    fgsm_correct += fgsm_pred.eq(target).sum().item()\n\n    # FGSM + Gaussian\n    adv_data_gauss = fgsm_gaussian_attack(model, loss_fn, data.clone(), target, epsilon)\n    adv_output_gauss = model(adv_data_gauss)\n    gauss_pred = adv_output_gauss.argmax(dim=1)\n    gaussian_correct += gauss_pred.eq(target).sum().item()\n\n    total_samples += target.size(0)\n\n\nprint(f\"\\nEvaluation on {total_samples} MNIST samples (ResNet18):\")\nprint(f\"Clean Accuracy         : {clean_correct}/{total_samples} = {clean_correct/total_samples*100:.2f}%\")\nprint(f\"FGSM Accuracy          : {fgsm_correct}/{total_samples} = {fgsm_correct/total_samples*100:.2f}%\")\nprint(f\"FGSM + Gaussian Accuracy: {gaussian_correct}/{total_samples} = {gaussian_correct/total_samples*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T19:22:27.907752Z","iopub.execute_input":"2025-04-22T19:22:27.908380Z","iopub.status.idle":"2025-04-22T19:28:16.864777Z","shell.execute_reply.started":"2025-04-22T19:22:27.908358Z","shell.execute_reply":"2025-04-22T19:28:16.863937Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning pretrained ResNet18 on MNIST for 1 epoch...\nEpoch 1, Loss: 0.06693653437562896\nFine-tuning complete.\nModel saved as 'finetuned_resnet18_mnist.pth'.\n\nEvaluation on 10000 MNIST samples (ResNet18):\nClean Accuracy         : 9791/10000 = 97.91%\nFGSM Accuracy          : 1251/10000 = 12.51%\nFGSM + Gaussian Accuracy: 9792/10000 = 97.92%\n","output_type":"stream"}],"execution_count":2}]}